{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import f_oneway\n",
    "from sklearn.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from operator import itemgetter\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_0</th>\n",
       "      <th>gene_1</th>\n",
       "      <th>gene_2</th>\n",
       "      <th>gene_3</th>\n",
       "      <th>gene_4</th>\n",
       "      <th>gene_6</th>\n",
       "      <th>gene_7</th>\n",
       "      <th>gene_8</th>\n",
       "      <th>gene_9</th>\n",
       "      <th>gene_10</th>\n",
       "      <th>...</th>\n",
       "      <th>gene_20523</th>\n",
       "      <th>gene_20524</th>\n",
       "      <th>gene_20525</th>\n",
       "      <th>gene_20526</th>\n",
       "      <th>gene_20527</th>\n",
       "      <th>gene_20528</th>\n",
       "      <th>gene_20529</th>\n",
       "      <th>gene_20530</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.017209</td>\n",
       "      <td>3.265527</td>\n",
       "      <td>5.478487</td>\n",
       "      <td>10.431999</td>\n",
       "      <td>7.175175</td>\n",
       "      <td>0.591871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.591871</td>\n",
       "      <td>...</td>\n",
       "      <td>9.723516</td>\n",
       "      <td>7.220030</td>\n",
       "      <td>9.119813</td>\n",
       "      <td>12.003135</td>\n",
       "      <td>9.650743</td>\n",
       "      <td>8.921326</td>\n",
       "      <td>5.286759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sample_0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>1.588421</td>\n",
       "      <td>7.586157</td>\n",
       "      <td>9.623011</td>\n",
       "      <td>6.816049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.740931</td>\n",
       "      <td>6.256586</td>\n",
       "      <td>8.381612</td>\n",
       "      <td>12.674552</td>\n",
       "      <td>10.517059</td>\n",
       "      <td>9.397854</td>\n",
       "      <td>2.094168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sample_1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.511759</td>\n",
       "      <td>4.327199</td>\n",
       "      <td>6.881787</td>\n",
       "      <td>9.870730</td>\n",
       "      <td>6.972130</td>\n",
       "      <td>0.452595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.908640</td>\n",
       "      <td>5.401607</td>\n",
       "      <td>9.911597</td>\n",
       "      <td>9.045255</td>\n",
       "      <td>9.788359</td>\n",
       "      <td>10.090470</td>\n",
       "      <td>1.683023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sample_2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.663618</td>\n",
       "      <td>4.507649</td>\n",
       "      <td>6.659068</td>\n",
       "      <td>10.196184</td>\n",
       "      <td>7.843375</td>\n",
       "      <td>0.434882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.141520</td>\n",
       "      <td>8.942805</td>\n",
       "      <td>9.601208</td>\n",
       "      <td>11.392682</td>\n",
       "      <td>9.694814</td>\n",
       "      <td>9.684365</td>\n",
       "      <td>3.292001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sample_3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.655741</td>\n",
       "      <td>2.821547</td>\n",
       "      <td>6.539454</td>\n",
       "      <td>9.738265</td>\n",
       "      <td>6.566967</td>\n",
       "      <td>0.360982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.373790</td>\n",
       "      <td>7.181162</td>\n",
       "      <td>9.846910</td>\n",
       "      <td>11.922439</td>\n",
       "      <td>9.217749</td>\n",
       "      <td>9.461191</td>\n",
       "      <td>5.110372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sample_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gene_0    gene_1    gene_2    gene_3     gene_4    gene_6    gene_7  \\\n",
       "0     0.0  2.017209  3.265527  5.478487  10.431999  7.175175  0.591871   \n",
       "1     0.0  0.592732  1.588421  7.586157   9.623011  6.816049  0.000000   \n",
       "2     0.0  3.511759  4.327199  6.881787   9.870730  6.972130  0.452595   \n",
       "3     0.0  3.663618  4.507649  6.659068  10.196184  7.843375  0.434882   \n",
       "4     0.0  2.655741  2.821547  6.539454   9.738265  6.566967  0.360982   \n",
       "\n",
       "   gene_8  gene_9   gene_10  ...  gene_20523  gene_20524  gene_20525  \\\n",
       "0     0.0     0.0  0.591871  ...    9.723516    7.220030    9.119813   \n",
       "1     0.0     0.0  0.000000  ...    9.740931    6.256586    8.381612   \n",
       "2     0.0     0.0  0.000000  ...   10.908640    5.401607    9.911597   \n",
       "3     0.0     0.0  0.000000  ...   10.141520    8.942805    9.601208   \n",
       "4     0.0     0.0  0.000000  ...   10.373790    7.181162    9.846910   \n",
       "\n",
       "   gene_20526  gene_20527  gene_20528  gene_20529  gene_20530  sample_id  \\\n",
       "0   12.003135    9.650743    8.921326    5.286759         0.0   sample_0   \n",
       "1   12.674552   10.517059    9.397854    2.094168         0.0   sample_1   \n",
       "2    9.045255    9.788359   10.090470    1.683023         0.0   sample_2   \n",
       "3   11.392682    9.694814    9.684365    3.292001         0.0   sample_3   \n",
       "4   11.922439    9.217749    9.461191    5.110372         0.0   sample_4   \n",
       "\n",
       "   Class  \n",
       "0      3  \n",
       "1      2  \n",
       "2      3  \n",
       "3      3  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 20266 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/cleaned/datacleaned.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.set_index(\"sample_id\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['Class'])\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a classification model, we must set aside certain proportion of our dataset for testing the performance of the model. However, there is a tricky issue with the current dataset. This gene expression dataset is very noisy. It has been found that there are genes which are only expressed in 20 percent or less samples. This means when we split the data n number of times, there might be certain splits where all the 0s fall in the training set, and all expression in the test set respectively. So, when we standardize the data using parameters of the training set, we might get a division by 0 on both the training and testing sets since the standard deviation of the genes in training set would be 0. \n",
    "\n",
    "Now since the sample set is relatively small, we must only choose the most important of all the informative features, and those features must be found only using the training set. For genes whose expression is mostly 0, there are 2 possibilities. Either the gene is expressed equally in all classes, in which case it is noise, or it is differentially expressed, in which case its relative importance wrt to other genes must be considered. But given the training size, we might end up completely ignoring these genes. \n",
    "\n",
    "In order to keep them, we must find out the maximum proportion of 0s in significant genes and split the data so that it doesn't exclude these genes automatically, except if this proportion is larger than 0.85. In order to give them a fair chance, we can do the following: First run ANOVA on the entire dataset to find out all differentially expressed genes, then find out the proportion of their zeros and split at the maximum proportion of zeros. That is, the splitting size \n",
    "\n",
    "s = min(0.85, max(proportion of zeros of all informative genes))\n",
    "\n",
    "This will ensure that training set contains at least one sample of such genes and so can be standardized and be directly fed to week 2 analysis of dimensionality reduction as well as wrapper based feature selection algorithms. If there are genes which are zero on more than 85% of samples and still significant, then those genes can be studied separately and will not be considered for classification model as they would only create the dataset noisy in different iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def F_test(gene, labels):\n",
    "    \n",
    "    \"\"\"\n",
    "    *************************************************\n",
    "    \n",
    "    Method to check if a given gene varies significantly across samples of different cancer types by using ANOVA test\n",
    "    \n",
    "    params:\n",
    "    gene: numpy array of expression of a given gene across all samples\n",
    "    labels: numpy array of corresponding labels of cancer type\n",
    "    \n",
    "    returns:\n",
    "    f: F-statistic\n",
    "    p: p-value\n",
    "    \n",
    "    \"\"\"\n",
    "    #convert to numpy arrays\n",
    "    genes = gene.values\n",
    "    labels = labels.values\n",
    "    #obtain expression of genes at different conditions\n",
    "    genes0 = genes[np.where(labels==0)]\n",
    "    genes1 = genes[np.where(labels==1)]\n",
    "    genes2 = genes[np.where(labels==2)]\n",
    "    genes3 = genes[np.where(labels==3)]\n",
    "    genes4 = genes[np.where(labels==4)]\n",
    "    #apply one way anova test\n",
    "    f,p = f_oneway(genes0,genes1,genes2,genes3,genes4)\n",
    "    \n",
    "    return f,p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countzeros(gene):\n",
    "    \"\"\"\n",
    "    counts zeros in a gene expression\n",
    "    \"\"\"\n",
    "    m = gene[gene==0].shape[0]\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum zero proportion in differentially expressed genes = 0.9975031210986267\n"
     ]
    }
   ],
   "source": [
    "cols = X.columns.to_list()\n",
    "significant_genes = [] #significant genes on the entire set\n",
    "n = X.shape[0]\n",
    "max_zero_prop = 0 # maximum proportion of zeros\n",
    "minimally_expressed_genes = []\n",
    "genes_to_remove = []\n",
    "\n",
    "for i in cols:\n",
    "    f,p = F_test(X[i],y)\n",
    "    m = countzeros(X[i])\n",
    "    zero_prop = m/n\n",
    "    if zero_prop > 0.85:\n",
    "        genes_to_remove.append(i)\n",
    "    if(p<0.05):\n",
    "        significant_genes.append((f,i, zero_prop))\n",
    "        \n",
    "        if zero_prop > 0.85:\n",
    "            minimally_expressed_genes.append(i) \n",
    "        \n",
    "        if zero_prop > max_zero_prop:\n",
    "            max_zero_prop = zero_prop\n",
    "    \n",
    "print(f\"maximum zero proportion in differentially expressed genes = {max_zero_prop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size = 0.15000000000000002\n"
     ]
    }
   ],
   "source": [
    "test_size = 1 - min(0.85,max(0.80,round(max_zero_prop*100 + 1)/100)) #test size shouldn't be greater than 0.2\n",
    "print(f\"Test size = {test_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total No. of genes dropped : 1252\n",
      "No. of differentially expressed genes dropped : 701\n"
     ]
    }
   ],
   "source": [
    "X1 = X.copy()\n",
    "X1 = X1.drop(columns = genes_to_remove)\n",
    "print(f\"Total No. of genes dropped : {len(genes_to_remove)}\")\n",
    "print(f\"No. of differentially expressed genes dropped : {len(minimally_expressed_genes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X1,y,test_size=test_size, random_state=10, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = X_train.copy()\n",
    "train['Class'] = y_train\n",
    "train.to_csv(\"datasets/cleaned/traindata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = X_test.copy()\n",
    "test['Class'] = y_test\n",
    "test.to_csv(\"datasets/cleaned/testdata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA (Filter based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18813"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perform ANOVA on training set\n",
    "traincols = X_train.columns.tolist()\n",
    "important_genes = []\n",
    "\n",
    "for i in traincols:\n",
    "    f,p = F_test(X_train[i],y_train)\n",
    "    if(p<0.05):\n",
    "        important_genes.append((f,i))\n",
    "        \n",
    "len(important_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sort important genes by F statistic: Higher F-statistic => lower p-value => more significant\n",
    "important_genes = sorted(important_genes, key=itemgetter(0), reverse=True)\n",
    "# select 500 most significant genes\n",
    "informative_genes = [gene for f,gene in important_genes[:500]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T08:50:02.334088Z",
     "iopub.status.busy": "2022-03-07T08:50:02.333822Z",
     "iopub.status.idle": "2022-03-07T08:50:02.346713Z",
     "shell.execute_reply": "2022-03-07T08:50:02.345748Z",
     "shell.execute_reply.started": "2022-03-07T08:50:02.334049Z"
    }
   },
   "source": [
    "## Stepwise Selection (Wrapper based)\n",
    "\n",
    "As p is very large (~20,264), stepwise selection for the entire feature space would be computationally very expensive (training 1 + p(p+1)/2 = 205,324,981 models for each method!!), therefore, we would use only the 500 informative features selected from ANOVA to perform each of Forward Selection and Backward Elimination. \n",
    "\n",
    "For both of the methods, we'd be using sklearn's SequentialFeatureSelector, select top 350 features so that both methods return atleast 200 common features. \n",
    "\n",
    "We'd also need a scoring method. F1 score is preferred because of class imbalance, however we'd need to define it custom as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f1_scorer = make_scorer(f1_score, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=4)]: Done 272 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   13.8s finished\n",
      "\n",
      "[2022-03-12 16:56:01] Features: 1/350 -- score: 0.7377746998090775[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=4)]: Done 499 out of 499 | elapsed:    6.8s finished\n",
      "\n",
      "[2022-03-12 16:56:08] Features: 2/350 -- score: 0.9292709767207553[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done 491 out of 498 | elapsed:    5.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 498 out of 498 | elapsed:    5.0s finished\n",
      "\n",
      "[2022-03-12 16:56:13] Features: 3/350 -- score: 0.9648366097888633[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 497 out of 497 | elapsed:    4.8s finished\n",
      "\n",
      "[2022-03-12 16:56:18] Features: 4/350 -- score: 0.9793682618219739[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 496 out of 496 | elapsed:    4.6s finished\n",
      "\n",
      "[2022-03-12 16:56:23] Features: 5/350 -- score: 0.9868495108737815[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 128 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=4)]: Done 495 out of 495 | elapsed:    4.1s finished\n",
      "\n",
      "[2022-03-12 16:56:27] Features: 6/350 -- score: 0.9941121673025979[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 494 out of 494 | elapsed:    4.1s finished\n",
      "\n",
      "[2022-03-12 16:56:31] Features: 7/350 -- score: 0.9970619063113322[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 128 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=4)]: Done 493 out of 493 | elapsed:    3.9s finished\n",
      "\n",
      "[2022-03-12 16:56:35] Features: 8/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 492 out of 492 | elapsed:    3.9s finished\n",
      "\n",
      "[2022-03-12 16:56:39] Features: 9/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 491 out of 491 | elapsed:    3.9s finished\n",
      "\n",
      "[2022-03-12 16:56:43] Features: 10/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 490 out of 490 | elapsed:    4.0s finished\n",
      "\n",
      "[2022-03-12 16:56:47] Features: 11/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 489 out of 489 | elapsed:    4.0s finished\n",
      "\n",
      "[2022-03-12 16:56:51] Features: 12/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 128 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=4)]: Done 488 out of 488 | elapsed:    3.9s finished\n",
      "\n",
      "[2022-03-12 16:56:55] Features: 13/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 487 out of 487 | elapsed:    4.3s finished\n",
      "\n",
      "[2022-03-12 16:57:00] Features: 14/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done 486 out of 486 | elapsed:    4.7s finished\n",
      "\n",
      "[2022-03-12 16:57:05] Features: 15/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 485 out of 485 | elapsed:    4.5s finished\n",
      "\n",
      "[2022-03-12 16:57:09] Features: 16/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 128 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=4)]: Done 484 out of 484 | elapsed:    4.2s finished\n",
      "\n",
      "[2022-03-12 16:57:14] Features: 17/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:    0.9s\n",
      "\n",
      "STOPPING EARLY DUE TO KEYBOARD INTERRUPT..."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    forwardm = load(\"week1/models/forwardsvcm.joblib\")\n",
    "except:\n",
    "    #prepare input data\n",
    "    X_fsm = X_train[informative_genes]\n",
    "    y_fsm = y_train.copy()\n",
    "    #define SFS model with Support Vector Classifier\n",
    "    pipefm = Pipeline([('scaler', StandardScaler()), ('estimator', SVC(kernel='linear'))])\n",
    "    forwardm = SFSM(pipefm, k_features=350, forward = True, scoring=f1_scorer, verbose=2, n_jobs=4)\n",
    "    #fit the SFS method\n",
    "    forwardm.fit(X_fsm,y_fsm)\n",
    "    #save the model\n",
    "    dump(forwardm,\"week1/models/forwardsvcm.joblib\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It can be seen that after 8 features validation score stopped increasing, indicating that features are redundant. Since mlxtend or sklearn don't provide earlystopping, the searching was manually stopped.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   24.8s finished\n",
      "\n",
      "[2022-03-12 17:19:24] Features: 499/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=4)]: Done 492 out of 499 | elapsed:   20.7s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 499 out of 499 | elapsed:   21.0s finished\n",
      "\n",
      "[2022-03-12 17:19:45] Features: 498/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=4)]: Done 498 out of 498 | elapsed:   21.1s finished\n",
      "\n",
      "[2022-03-12 17:20:07] Features: 497/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=4)]: Done 490 out of 497 | elapsed:   19.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 497 out of 497 | elapsed:   20.1s finished\n",
      "\n",
      "[2022-03-12 17:20:28] Features: 496/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=4)]: Done 496 out of 496 | elapsed:   21.8s finished\n",
      "\n",
      "[2022-03-12 17:20:50] Features: 495/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=4)]: Done 488 out of 495 | elapsed:   21.6s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 495 out of 495 | elapsed:   21.8s finished\n",
      "\n",
      "[2022-03-12 17:21:12] Features: 494/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=4)]: Done 487 out of 494 | elapsed:   21.4s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 494 out of 494 | elapsed:   21.6s finished\n",
      "\n",
      "[2022-03-12 17:21:34] Features: 493/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=4)]: Done 486 out of 493 | elapsed:   20.8s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 493 out of 493 | elapsed:   21.0s finished\n",
      "\n",
      "[2022-03-12 17:21:55] Features: 492/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=4)]: Done 485 out of 492 | elapsed:   21.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 492 out of 492 | elapsed:   21.4s finished\n",
      "\n",
      "[2022-03-12 17:22:17] Features: 491/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=4)]: Done 484 out of 491 | elapsed:   21.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 491 out of 491 | elapsed:   21.4s finished\n",
      "\n",
      "[2022-03-12 17:22:39] Features: 490/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=4)]: Done 490 out of 490 | elapsed:   22.0s finished\n",
      "\n",
      "[2022-03-12 17:23:02] Features: 489/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=4)]: Done 482 out of 489 | elapsed:   19.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 489 out of 489 | elapsed:   20.0s finished\n",
      "\n",
      "[2022-03-12 17:23:22] Features: 488/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=4)]: Done 488 out of 488 | elapsed:   20.6s finished\n",
      "\n",
      "[2022-03-12 17:23:43] Features: 487/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=4)]: Done 487 out of 487 | elapsed:   21.2s finished\n",
      "\n",
      "[2022-03-12 17:24:05] Features: 486/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=4)]: Done 479 out of 486 | elapsed:   20.5s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 486 out of 486 | elapsed:   20.7s finished\n",
      "\n",
      "[2022-03-12 17:24:26] Features: 485/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=4)]: Done 478 out of 485 | elapsed:   20.4s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 485 out of 485 | elapsed:   20.7s finished\n",
      "\n",
      "[2022-03-12 17:24:47] Features: 484/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=4)]: Done 477 out of 484 | elapsed:   21.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 484 out of 484 | elapsed:   21.2s finished\n",
      "\n",
      "[2022-03-12 17:25:09] Features: 483/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=4)]: Done 483 out of 483 | elapsed:   20.6s finished\n",
      "\n",
      "[2022-03-12 17:25:30] Features: 482/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=4)]: Done 482 out of 482 | elapsed:   21.1s finished\n",
      "\n",
      "[2022-03-12 17:25:51] Features: 481/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=4)]: Done 474 out of 481 | elapsed:   19.8s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 481 out of 481 | elapsed:   20.0s finished\n",
      "\n",
      "[2022-03-12 17:26:12] Features: 480/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=4)]: Done 480 out of 480 | elapsed:   20.6s finished\n",
      "\n",
      "[2022-03-12 17:26:33] Features: 479/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=4)]: Done 479 out of 479 | elapsed:   20.4s finished\n",
      "\n",
      "[2022-03-12 17:26:53] Features: 478/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:    2.6s\n",
      "\n",
      "STOPPING EARLY DUE TO KEYBOARD INTERRUPT..."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    backwardm = load(\"week1/models/backwardsvcm.joblib\")\n",
    "except:\n",
    "    #prepare the data\n",
    "    X_bem = X_train[informative_genes]\n",
    "    y_bem = y_train.copy()\n",
    "    #define SFS model with Support Vector Classifier\n",
    "    pipebm = Pipeline([('scaler', StandardScaler()), ('estimator', SVC(kernel='linear'))])\n",
    "    backwardm = SFSM(pipebm, k_features=350, forward = False, scoring = f1_scorer, verbose=2, n_jobs=4)\n",
    "    #fit the model\n",
    "    backwardm.fit(X_bem,y_bem)\n",
    "    #save the model\n",
    "    dump(backwardm, \"week1/models/backwardsvcm.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest Classifier\n",
    "\n",
    "#### Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:  4.6min finished\n",
      "\n",
      "[2022-03-12 15:18:35] Features: 1/350 -- score: 0.6989024297847701[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=4)]: Done 499 out of 499 | elapsed:  4.5min finished\n",
      "\n",
      "[2022-03-12 15:23:06] Features: 2/350 -- score: 0.9184096652246623[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=4)]: Done 498 out of 498 | elapsed:  4.4min finished\n",
      "\n",
      "[2022-03-12 15:27:29] Features: 3/350 -- score: 0.9718989119311221[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 497 out of 497 | elapsed:  4.6min finished\n",
      "\n",
      "[2022-03-12 15:32:05] Features: 4/350 -- score: 0.9838432985871194[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=4)]: Done 496 out of 496 | elapsed:  4.2min finished\n",
      "\n",
      "[2022-03-12 15:36:19] Features: 5/350 -- score: 0.9970600281654379[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done 495 out of 495 | elapsed:  4.1min finished\n",
      "\n",
      "[2022-03-12 15:40:25] Features: 6/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 494 out of 494 | elapsed:  4.0min finished\n",
      "\n",
      "[2022-03-12 15:44:24] Features: 7/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 493 out of 493 | elapsed:  3.8min finished\n",
      "\n",
      "[2022-03-12 15:48:11] Features: 8/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 492 out of 492 | elapsed:  3.9min finished\n",
      "\n",
      "[2022-03-12 15:52:05] Features: 9/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 491 out of 491 | elapsed:  3.9min finished\n",
      "\n",
      "[2022-03-12 15:55:57] Features: 10/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 490 out of 490 | elapsed:  3.9min finished\n",
      "\n",
      "[2022-03-12 15:59:51] Features: 11/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 489 out of 489 | elapsed:  3.9min finished\n",
      "\n",
      "[2022-03-12 16:03:45] Features: 12/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 488 out of 488 | elapsed:  3.9min finished\n",
      "\n",
      "[2022-03-12 16:07:39] Features: 13/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 487 out of 487 | elapsed:  3.9min finished\n",
      "\n",
      "[2022-03-12 16:11:32] Features: 14/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 486 out of 486 | elapsed:  3.9min finished\n",
      "\n",
      "[2022-03-12 16:15:25] Features: 15/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 485 out of 485 | elapsed:  4.6min finished\n",
      "\n",
      "[2022-03-12 16:20:00] Features: 16/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=4)]: Done 484 out of 484 | elapsed:  4.7min finished\n",
      "\n",
      "[2022-03-12 16:24:43] Features: 17/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=4)]: Done 483 out of 483 | elapsed:  4.3min finished\n",
      "\n",
      "[2022-03-12 16:29:01] Features: 18/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=4)]: Done 482 out of 482 | elapsed:  4.3min finished\n",
      "\n",
      "[2022-03-12 16:33:19] Features: 19/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=4)]: Done 481 out of 481 | elapsed:  4.3min finished\n",
      "\n",
      "[2022-03-12 16:37:35] Features: 20/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=4)]: Done 480 out of 480 | elapsed:  4.1min finished\n",
      "\n",
      "[2022-03-12 16:41:43] Features: 21/350 -- score: 0.9985209059868525[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   17.3s\n",
      "\n",
      "STOPPING EARLY DUE TO KEYBOARD INTERRUPT..."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    forward_rf = load(\"week1/models/forwardrf.joblib\")\n",
    "except:\n",
    "    #prepare input data\n",
    "    X_fs_rf = X_train[informative_genes]\n",
    "    y_fs_rf = y_train.copy()\n",
    "    #define SFS model with RandomForest Classifier\n",
    "    pipef_rf = Pipeline([('scaler', StandardScaler()), ('estimator', RandomForestClassifier(n_estimators=200,random_state=1))])\n",
    "    forward_rf = SFSM(pipef_rf, k_features=350, forward = True, scoring=f1_scorer, verbose=2, n_jobs=4)\n",
    "    #fit the SFS method\n",
    "    forward_rf.fit(X_fs_rf,y_fs_rf)\n",
    "    #save the model\n",
    "    dump(forward_rf,\"week1/models/forwardrf.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stepwise Selection : Analysis\n",
    "\n",
    "Again, it can be seen that removing features doesn't change validation scores, strongly indicating that useful feature set is much smaller and the total feature set contains lot of redundancy, i.e. features which do not contribute in any way. If we pre-specify the number of features to select, the algorithm will start listing all the redundant features in order to select the given number of features. **Therefore, search was manually stopped, and this method is discarded.** \n",
    "\n",
    "However, this application gives us new information about the data: If we look at f1 scores of the above 2 method, both the times it reaches 0.9985 and stops changing, indicating that features selected from ANOVA are very informative, and before feeding our data to these algorithms, we have succesfully removed most of the noise. It further suggests that we need a mechanism which looks at the bulk of the features and removes all the redundant features. \n",
    "\n",
    "In their landmark paper Guyon, I., Weston, J., Barnhill, S., & Vapnik, V., *“Gene selection for cancer classification using support vector machines”* propose a new method of gene selection utilizing Support Vector Machine methods based on **Recursive Feature Elimination (RFE)**. It's implementation is provided by scikit-learn's RFECV class. RFECV from scikit-learn recursively drops the least important features based on a model's `coef_` or `feature_importance_` attribute, after cross validating. The fraction of features to drop at each iteration is decided by the `step` parameter. Each of the resulting feature set is considered as a subset and is assigned a cross-validation score which is available in the attribute `grid_scores_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    recursive_svcm = load(\"week1/models/recursive_svcm.joblib\")\n",
    "except:\n",
    "    #prepare data\n",
    "    X_rfe_svcm = X_train[informative_genes].copy()\n",
    "    y_rfe_svcm = y_train.copy()\n",
    "    #define RFECV with SVC model\n",
    "    pipersvcm = Pipeline([('scaler', StandardScaler()), ('clf', SVC(kernel='linear'))])\n",
    "    recursive_svcm = RFECV(pipersvcm,step = 0.02, scoring = f1_scorer, importance_getter=lambda x:x[-1].coef_)\n",
    "    #fit the model\n",
    "    recursive_svcm.fit(X_rfe_svcm,y_rfe_svcm)\n",
    "    #save the model\n",
    "    #dump(recursive_svcm,\"week1/models/recursive_svcm.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get selected features\n",
    "selected_indices_recursive_svcm = recursive_svcm.get_support(indices=True)\n",
    "selected_feat_recursive_svcm = []\n",
    "for i,col in enumerate(X_rfe_svcm.columns.to_list()):\n",
    "    if i in selected_indices_recursive_svcm:\n",
    "        selected_feat_recursive_svcm.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recursive_svcm.score(X_rfe_svcm,y_rfe_svcm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    recursive_rfm = load(\"week1/models/recursive_rfm.joblib\")\n",
    "except:\n",
    "    #prepare data\n",
    "    X_rfe_rfm = X_train[informative_genes].copy()\n",
    "    y_rfe_rfm = y_train.copy()\n",
    "    #define RFECV with SVC model\n",
    "    piperrfm = Pipeline([('scaler', StandardScaler()), ('estimator', RandomForestClassifier(n_estimators=100))])\n",
    "    recursive_rfm = RFECV(piperrfm,step = 0.1, scoring = f1_scorer, importance_getter=lambda x: x[1].feature_importances_)\n",
    "    #fit the model\n",
    "    recursive_rfm.fit(X_rfe_rfm,y_rfe_rfm)\n",
    "    #save the model\n",
    "    #dump(recursive_rfm,\"week1/models/recursive_rfm.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get selected features\n",
    "selected_indices_recursive_rfm = recursive_rfm.get_support(indices=True)\n",
    "selected_feat_recursive_rfm = []\n",
    "for i,col in enumerate(X_rfe_rfm.columns.to_list()):\n",
    "    if i in selected_indices_recursive_rfm:\n",
    "        selected_feat_recursive_rfm.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recursive_rfm.score(X_rfe_rfm,y_rfe_rfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting common features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_feat_recursive_svcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_feat_recursive_rfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_feat = list(set(selected_feat_recursive_svcm).intersection(set(selected_feat_recursive_rfm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdata = X_train[common_feat].copy()\n",
    "trainingdata['Class'] = y_train\n",
    "testingdata = X_test[common_feat].copy()\n",
    "testingdata['Class'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdata.to_csv(\"datasets/featureselection/train.csv\")\n",
    "testingdata.to_csv(\"datasets/featureselection/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
